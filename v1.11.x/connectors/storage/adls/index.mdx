---
title: ADLS | Official Documentation
description: Connect Azure Data Lake Storage to Collate with our comprehensive ADLS connector guide. Setup instructions, configuration, and metadata extraction.
slug: /connectors/storage/adls
sidebarTitle: Overview
collate: true
---
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import TestConnection from '/snippets/connectors/test-connection.mdx'
import IngestionScheduleAndDeploy from '/snippets/connectors/ingestion-schedule-and-deploy.mdx'
import Manifest from '/snippets/connectors/storage/manifest.mdx'
import ConfigureIngestion from '/snippets/connectors/storage/configure-ingestion.mdx'

<ConnectorDetailsHeader
icon='/public/images/connectors/adls.webp'
name="ADLS"
stage="PROD"
availableFeatures={["Metadata", "Structured Containers"]}
unavailableFeatures={["Unstructured Containers"]} />
This page contains the setup guide and reference information for the ADLS connector.
Configure and schedule ADLS metadata workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
- [Troubleshooting](/connectors/storage/adls/troubleshooting)
## Requirements
We need the following permissions in Azure Data Lake Storage:
### ADLS Permissions
To extract metadata from Azure ADLS (Storage Account - StorageV2), you will need an **App Registration** with the following permissions on the Storage Account:
- Storage Blob Data Contributor
- Storage Queue Data Contributor
### OpenMetadata Manifest
In any other connector, extracting metadata happens automatically. In this case, we will be able to extract high-level
metadata from buckets, but in order to understand their internal structure we need users to provide an `openmetadata.json`
file at the bucket root.
`Supported File Formats: [ "csv",  "tsv", "avro", "parquet", "json", "json.gz", "json.zip" ]`
You can learn more about this [here](/connectors/storage). Keep reading for an example on the shape of the manifest file.
<Manifest />
## Metadata Ingestion
<Steps>
<Step title="Visit the Services Page">
  The first step is ingesting the metadata from your sources. Under
Settings, you will find a Services link an external source system to
OpenMetadata. Once a service is created, it can be used to configure
metadata, usage, and profiler workflows.
To visit the Services page, select Services from the Settings menu.
  <img src="/public/images/connectors/visit-services-page.png" alt="Visit Services Page" />
</Step>
<Step title="Create a New Service">
  Click on the 'Add New Service' button to start the Service creation.
  <img src="/public/images/connectors/create-new-service.png" alt="Create a new service" />
</Step>
<Step title="Select the Service Type">
  Select ADLS as the service type and click Next.
  <img src="/public/images/connectors/adls/select-service.png" alt="Select Service" />
</Step>
<Step title="Name and Describe your Service">
  Provide a name and description for your service.
#### Service Name
OpenMetadata uniquely identifies services by their Service Name. Provide
a name that distinguishes your deployment from other services, including
the other Storage services that you might be ingesting metadata
from.
  <img src="/public/images/connectors/adls/add-new-service.png" alt="Add New Service" />
</Step>
<Step title="Configure the Service Connection">
  In this step, we will configure the connection settings required for
this connector. Please follow the instructions below to ensure that
you've configured the connector to read from your ADLS service as
desired.
  <img src="/public/images/connectors/adls/service-connection.png" alt="Configure service connection" />
</Step>
<Step title="Connection Details">
<Tip>
When using a **Hybrid Ingestion Runner**, any sensitive credential fields—such as passwords, API keys, or private keys—must reference secrets using the following format:
```
password: secret:/my/database/password
```
This applies **only to fields marked as secrets** in the connection form (these typically mask input and show a visibility toggle icon).
For a complete guide on managing secrets in hybrid setups, see the [Hybrid Ingestion Runner Secret Management Guide](https://docs.getcollate.io/getting-started/day-1/hybrid-saas/hybrid-ingestion-runner#3.-manage-secrets-securely).
</Tip>
**Client ID**: This unique identifier is assigned to your Azure Service Principal App, serving as a key for authentication and authorization.
**Client Secret**: This confidential password is associated with the Service Principal, safeguarding access to Azure resources and ensuring secure communication.
**Tenant ID**: Identifying your Azure Subscription, the Tenant ID links your resources to a specific organization or account within the Azure Active Directory.
**Storage Account Name**: This is the user-defined name for your Azure Storage Account, providing a globally unique namespace for your data.
**Key Vault Name**: Azure Key Vault serves as a centralized secrets manager, securely storing and managing sensitive information, such as connection strings and cryptographic keys.
</Step>
<TestConnection />
<ConfigureIngestion />
<IngestionScheduleAndDeploy />
</Steps>
