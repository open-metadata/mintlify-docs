---
title: Run the Atlas Connector Externally
description: Use YAML to ingest metadata from Apache Atlas including classifications, glossary, and lineage.
slug: /connectors/metadata/atlas/yaml
sidebarTitle: Run Externally
mode: "wide"
---
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import WorkflowConfigDef from '/snippets/connectors/yaml/workflow-config-def.mdx'
import IngestionCli from '/snippets/connectors/yaml/ingestion-cli.mdx'
import PythonRequirements from '/snippets/connectors/python-requirements.mdx'
import ExternalIngestionDeployment from '/snippets/connectors/external-ingestion-deployment.mdx'
import WorkflowConfig from '/snippets/connectors/yaml/workflow-config.mdx'
import { CodePreview, ContentPanel, ContentSection, CodePanel } from '/snippets/components/CodePreview.jsx'

<ConnectorDetailsHeader
icon='/public/images/connectors/atlas.webp'
name="Atlas"
stage="PROD"
availableFeatures={["Metadata"]}
unavailableFeatures={[]} />
In this section, we provide guides and references to use the Atlas connector.
Configure and schedule Atlas metadata and profiler workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
<ExternalIngestionDeployment />
## Requirements
Before this, you must ingest the database / messaging service you want to get metadata for.
For more details click [here](/connectors/metadata/atlas#1.-create-database-&-messaging-services)
### Python Requirements
<PythonRequirements />
To run the Atlas ingestion, you will need to install:
```bash
pip3 install "openmetadata-ingestion[atlas]"
```
## Metadata Ingestion
All connectors are defined as JSON Schemas.
[Here](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/entity/services/connections/metadata/atlasConnection.json)
you can find the structure to create a connection to Atlas.
In order to create and run a Metadata Ingestion workflow, we will follow
the steps to create a YAML configuration able to connect to the source,
process the Entities if needed, and reach the OpenMetadata server.
The workflow is modeled around the following
[JSON Schema](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/metadataIngestion/workflow.json)
### 1. Define the YAML Config

<CodePreview>

<ContentPanel>

<ContentSection id={1} title="Source Configuration" lines="1-3">

Configure the source type and service name for your Atlas connector.

</ContentSection>

<ContentSection id={2} title="Host Port" lines="7">

**hostPort**: Atlas Host of the data source.

</ContentSection>

<ContentSection id={3} title="Username" lines="8">

**username**: Username to connect to the Atlas. This user should have privileges to read all the metadata in Atlas.

</ContentSection>

<ContentSection id={4} title="Password" lines="9">

**password**: Password to connect to the Atlas.

</ContentSection>

<ContentSection id={5} title="Database Service Name" lines="10">

**databaseServiceName**: source database of the data source (Database service that you created from UI. example- local_hive).

</ContentSection>

<ContentSection id={6} title="Messaging Service Name" lines="11">

**messagingServiceName**: messaging service source of the data source.

</ContentSection>

<ContentSection id={7} title="Entity Type" lines="12">

**entity_type**: Name of the entity type in Atlas.

</ContentSection>

<ContentSection id={8} title="Source Config" lines="13-15">

Configure the metadata ingestion type as DatabaseMetadata.

</ContentSection>

<ContentSection id={9} title="Sink Configuration" lines="16-18">

To send the metadata to OpenMetadata, it needs to be specified as `type: metadata-rest`.

</ContentSection>

<ContentSection id={10} title="Workflow Configuration" lines="19-35">

<WorkflowConfigDef />

</ContentSection>

</ContentPanel>

<CodePanel fileName="atlas_config.yaml">

```yaml
source:
  type: Atlas
  serviceName: local_atlas
  serviceConnection:
    config:
      type: Atlas
      hostPort: http://localhost:10000
      username: username
      password: password
      databaseServiceName: ["local_hive"]
      messagingServiceName: []
      entity_type: Table
  sourceConfig:
    config:
      type: DatabaseMetadata
sink:
  type: metadata-rest
  config: {}
```

<WorkflowConfig />
</CodePanel>
</CodePreview>
<IngestionCli />
