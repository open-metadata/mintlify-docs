---
title: Redpanda Connector | Collate Messaging Services
description: Connect Collate to Redpanda with our official messaging connector. Stream metadata, automate discovery, and integrate your Kafka-compatible platform seamlessly.
slug: /connectors/messaging/redpanda
sidebarTitle: Overview
---
import ConfigureIngestion from '/snippets/connectors/messaging/configure-ingestion.mdx'
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import TestConnection from '/snippets/connectors/test-connection.mdx'
import IngestionScheduleAndDeploy from '/snippets/connectors/ingestion-schedule-and-deploy.mdx'
import { MetadataIngestionUi } from '/snippets/components/MetadataIngestionUi.jsx'

<ConnectorDetailsHeader
icon='/public/images/connectors/redpanda.webp'
name="Redpanda"
stage="PROD"
availableFeatures={["Topics", "Sample Data"]}
unavailableFeatures={[]} />
In this section, we provide guides and references to use the Redpanda connector.
Configure and schedule Redpanda metadata and profiler workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
- [Troubleshooting](/connectors/messaging/redpanda/troubleshooting)
## Requirements
Connecting to Redpanda does not require any previous configuration.
The ingestion of the Kafka topics' schema is done separately by configuring the **Schema Registry URL**. However, only the **Bootstrap Servers** information is mandatory.
## Metadata Ingestion
<MetadataIngestionUi connector={"Redpanda"} selectServicePath={"/public/images/connectors/redpanda/select-service.png"} addNewServicePath={"/public/images/connectors/redpanda/add-new-service.png"} serviceConnectionPath={"/public/images/connectors/redpanda/service-connection.png"} />
# Connection Details
<Steps>
<Step title="Connection Details">
<Tip>
When using a **Hybrid Ingestion Runner**, any sensitive credential fields—such as passwords, API keys, or private keys—must reference secrets using the following format:
```
password: secret:/my/database/password
```
This applies **only to fields marked as secrets** in the connection form (these typically mask input and show a visibility toggle icon).
For a complete guide on managing secrets in hybrid setups, see the [Hybrid Ingestion Runner Secret Management Guide](https://docs.getcollate.io/getting-started/day-1/hybrid-saas/hybrid-ingestion-runner#3.-manage-secrets-securely).
</Tip>
- **Bootstrap Servers**: List of brokers as comma separated values of broker `host` or `host:port`. Example: `host1:9092,host2:9092`
- **Schema Registry URL**: URL of the Schema Registry used to ingest the schemas of the topics.
- **SASL Username**: SASL username for use with the PLAIN and SASL-SCRAM mechanisms.
- **SASL Password**: SASL password for use with the PLAIN and SASL-SCRAM mechanisms.
- **SASL Mechanism**: SASL mechanism to use for authentication.
- **Basic Auth User Info**: Schema Registry Client HTTP credentials in the form of `username:password`. By default, user info is extracted from the URL if present.
- **Consumer Config**: The accepted additional values for the consumer configuration can be found in the following [link](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.mdx).
- **Schema Registry Config**: The accepted additional values for the Schema Registry configuration can be found in the following [link](https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#schemaregistryclient).
<Tip>
To ingest the topic schema `Schema Registry URL` must be passed
</Tip>
</Step>
<TestConnection />
<ConfigureIngestion />
<IngestionScheduleAndDeploy />
</Steps>
