---
title: Run the Airbyte Connector Externally
description: Use YAML to configure Airbyte ingestion and extract metadata from pipeline sources and syncs.
slug: /connectors/pipeline/airbyte/yaml
sidebarTitle: Run Externally
mode: "wide"
---
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import { CodePreview, ContentPanel, ContentSection, CodePanel } from '/snippets/components/CodePreview.jsx'
import SourceConfigDef from '/snippets/connectors/yaml/pipeline/source-config-def.mdx'
import SourceConfig from '/snippets/connectors/yaml/pipeline/source-config.mdx'
import IngestionSinkDef from '/snippets/connectors/yaml/ingestion-sink-def.mdx'
import WorkflowConfigDef from '/snippets/connectors/yaml/workflow-config-def.mdx'
import IngestionCli from '/snippets/connectors/yaml/ingestion-cli.mdx'
import PythonRequirements from '/snippets/connectors/python-requirements.mdx'
import ExternalIngestionDeployment from '/snippets/connectors/external-ingestion-deployment.mdx'
import IngestionSink from '/snippets/connectors/yaml/ingestion-sink.mdx'
import WorkflowConfig from '/snippets/connectors/yaml/workflow-config.mdx'

<ConnectorDetailsHeader
icon='/public/images/connectors/airbyte.webp'
name="Airbyte"
stage="PROD"
availableFeatures={["Pipelines", "Pipeline Status", "Lineage", "Usage"]}
unavailableFeatures={["Owners", "Tags"]} />
In this section, we provide guides and references to use the Airbyte connector.
Configure and schedule Airbyte metadata and profiler workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
<ExternalIngestionDeployment />
## Requirements
### Python Requirements
<PythonRequirements />
To run the Airbyte ingestion, you will need to install:
```bash
pip3 install "openmetadata-ingestion[airbyte]"
```
## Metadata Ingestion
All connectors are defined as JSON Schemas.
[Here](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/entity/services/connections/pipeline/airbyteConnection.json)
you can find the structure to create a connection to Airbyte.
In order to create and run a Metadata Ingestion workflow, we will follow
the steps to create a YAML configuration able to connect to the source,
process the Entities if needed, and reach the OpenMetadata server.
The workflow is modeled around the following
[JSON Schema](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/metadataIngestion/workflow.json)
### 1. Define the YAML Config
This is a sample config for Airbyte:
<CodePreview>
<ContentPanel>
<ContentSection id={1} title="hostPort" lines="7">
**hostPort**: Pipeline Service Management UI URL
</ContentSection>
<ContentSection id={2} title="username" lines="8">
**username**: Username to connect to Airbyte.
</ContentSection>
<ContentSection id={3} title="password" lines="9">
**password**: Password to connect to Airbyte.
</ContentSection>
<ContentSection id={4} title="apiVersion" lines="10">
**apiVersion**: Version of the Airbyte REST API by default `api/v1`.
</ContentSection>
<ContentSection id={3} title="SourceConfig" lines="11-30">
<SourceConfigDef />
</ContentSection>
<IngestionSinkDef />
<WorkflowConfigDef />
</ContentPanel>
<CodePanel fileName="connector_config.yaml">
```yaml
source:
  type: airbyte
  serviceName: airbyte_source
  serviceConnection:
    config:
      type: Airbyte
      hostPort: http://localhost:8000
      username: <username>
      password: <password>
      apiVersion: api/v1
```
<SourceConfig />
<IngestionSink />
<WorkflowConfig />
</CodePanel>
</CodePreview>
<IngestionCli />
