---
title: Spline Connector | Collate Data Lineage Integration
description: Connect Spline data lineage to Collate with our pipeline connector. Track data flow, automate metadata ingestion, and enhance governance seamlessly.
slug: /connectors/pipeline/spline
sidebarTitle: Overview
---
import ConfigureIngestion from '/snippets/connectors/pipeline/configure-ingestion.mdx'
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import TestConnection from '/snippets/connectors/test-connection.mdx'
import IngestionScheduleAndDeploy from '/snippets/connectors/ingestion-schedule-and-deploy.mdx'
import { MetadataIngestionUi } from '/snippets/components/MetadataIngestionUi.jsx'

<ConnectorDetailsHeader
icon='/public/images/connectors/spline.webp'
name="Spline"
stage="BETA"
availableFeatures={["Pipelines", "Pipeline Status", "Usage"]}
unavailableFeatures={["Owners", "Tags", "Lineage"]} />
In this section, we provide guides and references to use the Spline connector.
Configure and schedule Spline metadata and profiler workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
- [Troubleshooting](/connectors/pipeline/spline/troubleshooting)
## Requirements
The Spline connector supports lineage of data source of type `jdbc` or `dbfs` i.e. The Spline connector would be able to extract lineage if the data source is either a jdbc connection or the data source is a Databricks instance.
<Tip>
Currently, we do not support data source of type AWS S3 or any other cloud storage, which also means that the lineage for external tables from Databricks will not be extracted.
</Tip>
You can refer [this](https://github.com/AbsaOSS/spline-getting-started/tree/main/spline-on-databricks) documentation on how to configure Databricks with Spline.
## Metadata Ingestion
<MetadataIngestionUi connector={"Spline"} selectServicePath={"/public/images/connectors/spline/select-service.png"} addNewServicePath={"/public/images/connectors/spline/add-new-service.png"} serviceConnectionPath={"/public/images/connectors/spline/service-connection.png"} />
# Connection Details
<Steps>
<Step title="Connection Details">
<Tip>
When using a **Hybrid Ingestion Runner**, any sensitive credential fields—such as passwords, API keys, or private keys—must reference secrets using the following format:
```
password: secret:/my/database/password
```
This applies **only to fields marked as secrets** in the connection form (these typically mask input and show a visibility toggle icon).
For a complete guide on managing secrets in hybrid setups, see the [Hybrid Ingestion Runner Secret Management Guide](https://docs.getcollate.io/getting-started/day-1/hybrid-saas/hybrid-ingestion-runner#3.-manage-secrets-securely).
</Tip>
- **Spline REST Server Host & Port**: OpenMetadata uses Spline REST Server APIs to extract the execution details from spline to generate lineage. This should be specified as a URI string in the format `scheme://hostname:port`. E.g., `http://localhost:8080`, `http://host.docker.internal:8080`.
- **Spline UI Host & Port**: Spline UI Host & Port is an optional field which is used for generating redirection URL from OpenMetadata to Spline Portal. This should be specified as a URI string in the format `scheme://hostname:port`. E.g., `http://localhost:9090`, `http://host.docker.internal:9090`.
</Step>
<TestConnection />
<ConfigureIngestion />
<IngestionScheduleAndDeploy />
</Steps>
