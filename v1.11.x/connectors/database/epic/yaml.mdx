---
title: Run the Epic FHIR Connector Externally
description: Configure Epic FHIR ingestion using YAML to automate FHIR resource metadata collection.
slug: /connectors/database/epic/yaml
sidebarTitle: Run Externally
Collate: true
mode: "wide"
---
import { ConnectorDetailsHeader } from '/snippets/components/ConnectorDetailsHeader/ConnectorDetailsHeader.jsx'
import { CodePreview, ContentPanel, ContentSection, CodePanel } from '/snippets/components/CodePreview.jsx'
import IngestionSinkDef from '/snippets/connectors/yaml/ingestion-sink-def.mdx'
import WorkflowConfigDef from '/snippets/connectors/yaml/workflow-config-def.mdx'
import ExternalIngestionDeployment from '/snippets/connectors/external-ingestion-deployment.mdx'
import IngestionSink from '/snippets/connectors/yaml/ingestion-sink.mdx'
import WorkflowConfig from '/snippets/connectors/yaml/workflow-config.mdx'
import SourceConfig from '/snippets/connectors/yaml/database/source-config.mdx'
import SourceConfigDef from '/snippets/connectors/yaml/database/source-config-def.mdx'

<ConnectorDetailsHeader
icon='/public/images/connectors/epic.png'
name="Epic"
stage="BETA"
availableFeatures={["Metadata"]}
unavailableFeatures={["Data Profiler", "Data Quality", "dbt", "Lineage", "Column-level Lineage", "Query Usage", "Owners", "Tags", "Sample Data", "Reverse Metadata (Collate Only)", "Auto-Classification", "Stored Procedures"]} />
In this section, we provide guides and references to use the Epic FHIR connector.
Configure and schedule Epic metadata workflows from the OpenMetadata UI:
- [Requirements](#requirements)
- [Metadata Ingestion](#metadata-ingestion)
<ExternalIngestionDeployment />
## Requirements
To run the Epic ingestion, install the Python package:
```bash
pip3 install "openmetadata-ingestion[epic]"
```
## Metadata Ingestion
All connectors are defined as JSON Schemas.
[Here](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/entity/services/connections/database/epicConnection.json) you can find the structure to create a connection to Epic.
The ingestion workflow itself follows the general [workflow schema](https://github.com/open-metadata/OpenMetadata/blob/main/openmetadata-spec/src/main/resources/json/schema/metadataIngestion/workflow.json).
### 1. Define the YAML Config

<CodePreview>

<ContentPanel>

<ContentSection id={1} title="Source Configuration" lines="1-3">

Configure the source type and service name for your Epic FHIR connector.

</ContentSection>

<ContentSection id={2} title="FHIR Server URL" lines="7">

**fhirServerUrl**: Base URL of the Epic FHIR server.

</ContentSection>

<ContentSection id={3} title="FHIR Version" lines="8">

**fhirVersion**: FHIR specification version supported (`R4`, `STU3`, or `DSTU2`).

</ContentSection>

<ContentSection id={4} title="Database Name" lines="10">

**databaseName**: Optional name for the database in OpenMetadata. Defaults to `epic`.

</ContentSection>

<ContentSection id={5} title="Filter Patterns" lines="11-54">

**schemaFilterPattern / tableFilterPattern**: Regex filters to limit which FHIR resource categories (schemas) or resource types (tables) are ingested.

</ContentSection>


<ContentSection id={6} title="Source Config" lines="11-54">

<SourceConfigDef />

</ContentSection>

<ContentSection id={7} title="Sink Configuration" lines="55-57">

<IngestionSinkDef />

</ContentSection>

<ContentSection id={8} title="Workflow Configuration" lines="58-74">

<WorkflowConfigDef />

</ContentSection>

</ContentPanel>

<CodePanel fileName="epic_config.yaml">

```yaml
source:
  type: epic
  serviceName: epic_fhir
  serviceConnection:
    config:
      type: Epic
      fhirServerUrl: https://fhir.epic.com/interconnect-fhir-oauth/api/FHIR/R4  # REQUIRED
      fhirVersion: R4  # REQUIRED
      # Optional:
      # databaseName: epic
```

<SourceConfig />

<IngestionSink />

<WorkflowConfig />

</CodePanel>

</CodePreview>
